{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81a1094-0933-45a6-b060-c25c69349ab4",
   "metadata": {},
   "source": [
    "Q1. A contingency matrix, also known as a confusion matrix, is a table that is used to evaluate the performance of a classification model. It shows the counts of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions made by the model. It is typically used to calculate various performance metrics such as accuracy, precision, recall, F1-score, and more.\n",
    "\n",
    "Q2. A pair confusion matrix is a variation of a regular confusion matrix that is used when evaluating the performance of information retrieval systems, particularly in cases where documents are retrieved in pairs or sets (e.g., in document retrieval or recommendation systems). It extends the concept of true positives, false positives, true negatives, and false negatives to pairs of documents or items, allowing for the assessment of the system's ability to retrieve relevant pairs.\n",
    "\n",
    "Q3. In the context of natural language processing (NLP), an extrinsic measure is an evaluation metric that assesses the performance of an NLP system or language model within a specific application or task. It measures how well the model performs in a real-world scenario, such as machine translation, text summarization, or sentiment analysis, by considering the system's output and its impact on the task's objective.\n",
    "\n",
    "Q4. Intrinsic measures in the context of machine learning are evaluation metrics that assess the performance of a model based on its internal characteristics, without considering its performance in a specific application or task. These measures are often used during model development and training to fine-tune hyperparameters, optimize model architecture, or monitor convergence. Intrinsic measures differ from extrinsic measures, which evaluate a model's performance in real-world applications.\n",
    "\n",
    "Q5. The purpose of a confusion matrix in machine learning is to provide a detailed breakdown of a model's predictions and their correspondence to ground truth labels. It helps identify the strengths and weaknesses of a model in terms of classification performance. For example, it can reveal whether a model tends to make more false positives or false negatives, which can be critical information for model improvement.\n",
    "\n",
    "Q6. Common intrinsic measures used to evaluate the performance of unsupervised learning algorithms include:\n",
    "\n",
    "   - Silhouette Score: Measures the quality of clustering by evaluating the similarity of data points within the same cluster compared to data points in other clusters. A higher score indicates better-defined clusters.\n",
    "   - Davies-Bouldin Index: Measures the average similarity ratio of each cluster with the cluster that is most similar to it. Lower values indicate better clustering.\n",
    "   - Inertia: Measures the within-cluster sum of squares, indicating how tightly data points are clustered within each cluster.\n",
    "\n",
    "These measures provide insights into the quality of clustering results or dimensionality reduction techniques.\n",
    "\n",
    "Q7. Limitations of using accuracy as a sole evaluation metric for classification tasks include:\n",
    "\n",
    "   - Imbalanced Datasets: Accuracy can be misleading when dealing with imbalanced datasets, where one class significantly outnumbers the others. The model can achieve high accuracy by simply predicting the majority class.\n",
    "   - Ignoring Misclassification Costs: Accuracy treats all errors equally, whereas in many real-world applications, misclassifying one class may have more severe consequences than misclassifying another.\n",
    "   - Lack of Information: Accuracy does not provide a detailed breakdown of errors, making it challenging to identify which classes the model struggles with.\n",
    "\n",
    "These limitations can be addressed by using additional metrics such as precision, recall, F1-score, and the confusion matrix, which offer a more comprehensive view of classification performance, particularly in imbalanced or cost-sensitive scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870550b-350a-4641-bc3f-269179d1fa70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
